<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Projects on Hugo Veríssimo</title><link>https://hugoverissimo21.github.io/projects/</link><description>Recent content in Projects on Hugo Veríssimo</description><generator>Hugo</generator><language>en</language><lastBuildDate>Mon, 16 Jun 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://hugoverissimo21.github.io/projects/index.xml" rel="self" type="application/rss+xml"/><item><title>Smart Workbench</title><link>https://hugoverissimo21.github.io/projects/smartworkbench/</link><pubDate>Mon, 16 Jun 2025 00:00:00 +0000</pubDate><guid>https://hugoverissimo21.github.io/projects/smartworkbench/</guid><description>&lt;p>As part of the Master&amp;rsquo;s Degree in Data Science at the University of Aveiro, in the Seminar course, our class created a fictitious startup called Smart Workbench, aiming to develop a system based on unstructured data (cameras) and structured data (timings and logs) to automate and optimize a production line.&lt;/p>
&lt;p>The goal was to maximize line efficiency by reducing wait times and increasing productivity through data analysis and the use of machine learning and deep learning algorithms, helping predict failures, optimize processes, and reduce operators&amp;rsquo; cognitive load.&lt;/p></description></item><item><title>Sorting Algorithms</title><link>https://hugoverissimo21.github.io/projects/sortingalgorithms/</link><pubDate>Fri, 13 Jun 2025 00:00:00 +0000</pubDate><guid>https://hugoverissimo21.github.io/projects/sortingalgorithms/</guid><description>&lt;p>This project includes implementations and comparative tests in Python of nine important sorting algorithms: Bubble Sort, Selection Sort, Insertion Sort, Counting Sort, Radix Sort, Quick Sort, Merge Sort, Heap Sort, and Timsort.&lt;/p>
&lt;p>The main goal was to theoretically explore the operation, complexity, and stability of each algorithm, as well as to run empirical tests on random lists of various sizes and characteristics. Results were validated through performance analysis and charts.&lt;/p></description></item><item><title>Electricity Consumption Forecast in Spain</title><link>https://hugoverissimo21.github.io/projects/electricityforecast/</link><pubDate>Wed, 11 Jun 2025 00:00:00 +0000</pubDate><guid>https://hugoverissimo21.github.io/projects/electricityforecast/</guid><description>&lt;p>This project focuses on forecasting electricity consumption in Spain, based on historical data provided by EuroStat. The main objective was to develop a robust and accurate forecasting model to support power grid management and strategic energy decision-making.&lt;/p>
&lt;p>Several statistical time series methods were explored, including ARIMA, GARCH, ETS, and STLM, to model electricity consumption over time. Each model was properly tuned, where applicable, and statistically validated, then compared using error metrics such as RMSE and MAPE.&lt;/p></description></item><item><title>Sentiment Analysis of Financial Phrases</title><link>https://hugoverissimo21.github.io/projects/finphrasebank/</link><pubDate>Tue, 10 Jun 2025 00:00:00 +0000</pubDate><guid>https://hugoverissimo21.github.io/projects/finphrasebank/</guid><description>&lt;p>This project focused on sentiment analysis of financial phrases, based on the FinPhraseBank dataset, which contains sentences extracted from financial reports and news articles. The goal was to develop a model capable of classifying the sentiment of these phrases as positive, negative, or neutral, thus contributing to a better understanding of the emotional impact of financial information.&lt;/p>
&lt;p>The subset with 75% annotator agreement was used to ensure higher reliability of the labels. Of this dataset, 80% was used for training and 20% for testing, ensuring accurate performance evaluation.&lt;/p></description></item><item><title>CPI Anomaly Detector</title><link>https://hugoverissimo21.github.io/projects/cpianomalies/</link><pubDate>Tue, 27 May 2025 00:00:00 +0000</pubDate><guid>https://hugoverissimo21.github.io/projects/cpianomalies/</guid><description>&lt;p>This project aims to detect anomalies in the Consumer Price Index (CPI), a key indicator used to measure inflation and the cost of living. The motivation is to identify unexpected and significant changes in consumer prices to support the analysis of economic dynamics and strategic decision-making.&lt;/p>
&lt;p>Public data from over 200 countries was used to develop an adaptive, real-time (streaming) model capable of automatically detecting anomalies. The main model is based on Long Short-Term Memory (LSTM) networks, with a focus on economic time series.&lt;/p></description></item><item><title>LSH Recommender System</title><link>https://hugoverissimo21.github.io/projects/lshrecommender/</link><pubDate>Tue, 27 May 2025 00:00:00 +0000</pubDate><guid>https://hugoverissimo21.github.io/projects/lshrecommender/</guid><description>&lt;p>Creation and benchmarking of a rating prediction algorithm based on LSH (Locality Sensitive Hashing) for large volumes of data from the MovieLens dataset. The goal is to predict a user&amp;rsquo;s rating for a specific movie, using advanced hashing techniques to optimize the search for similarities between users and movies.&lt;/p>
&lt;p>The algorithm was implemented in a high-performance computing environment, executed via SSH with distributed jobs on Apache Spark. This approach enables analysis and recommendation on large-scale datasets, ranging from 100 thousand to 25 million ratings, demonstrating the scalability and efficiency of the system in big data contexts.&lt;/p></description></item><item><title>Lupa Digital</title><link>https://hugoverissimo21.github.io/projects/lupadigital25/</link><pubDate>Tue, 06 May 2025 00:00:00 +0000</pubDate><guid>https://hugoverissimo21.github.io/projects/lupadigital25/</guid><description>&lt;p>Lupa Digital is a project developed within the scope of the Arquivo.pt Awards 2025 competition, focused on intelligent metajournalism. Using artificial intelligence tools, the project analyzes thousands of journalistic articles since the dawn of the digital era to discover patterns, trends, and relevant insights on any topic. The goal is to transform large volumes of journalistic information into useful and accessible knowledge, contributing to the strengthening of media literacy and a more critical understanding of the information ecosystem.&lt;/p></description></item><item><title>Counting Photovoltaic and Solar Panels from Aerial Images</title><link>https://hugoverissimo21.github.io/projects/solarpanel-dlcounter/</link><pubDate>Mon, 05 May 2025 00:00:00 +0000</pubDate><guid>https://hugoverissimo21.github.io/projects/solarpanel-dlcounter/</guid><description>&lt;p>This project aims to count photovoltaic and solar panels from aerial images using Deep Learning and Computer Vision techniques. It was developed as part of the Zindi Lacuna competition, which provided images of panels in Madagascar.&lt;/p>
&lt;p>The work involved data cleaning and preprocessing, including correction of various polygons.&lt;/p>
&lt;div style="display: flex; align-items: center; gap: 20px;">
 &lt;div style="flex: 1;">
 &lt;p>Creation of hybrid models combining ResNet, EfficientNet, and DenseNet to extract image features, with an attention head to aggregate features extracted from image metadata, for subsequent regression of the number of each panel type.&lt;/p></description></item><item><title>Quantitative Research @ JPMorgan Chase &amp; Co.</title><link>https://hugoverissimo21.github.io/projects/jpm-quantitative-models/</link><pubDate>Thu, 06 Mar 2025 00:00:00 +0000</pubDate><guid>https://hugoverissimo21.github.io/projects/jpm-quantitative-models/</guid><description>&lt;p>This project uses quantitative research methods, machine learning, and data analysis to solve challenges in the financial and energy sectors. The analysis focuses on developing pricing models for natural gas contracts, estimating loan default probabilities, and forecasting losses for banks. Techniques such as K-means clustering, machine learning methods, and time series decomposition were employed to provide actionable insights.&lt;/p>
&lt;p>Project highlights:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Development of a prototype pricing model for natural gas contracts, based on estimated prices for buying/selling on specific dates, gas injection/withdrawal rates in storage, and associated costs.&lt;/p></description></item><item><title>Recommender Systems</title><link>https://hugoverissimo21.github.io/projects/mldriven-collabfilter/</link><pubDate>Sat, 25 Jan 2025 00:00:00 +0000</pubDate><guid>https://hugoverissimo21.github.io/projects/mldriven-collabfilter/</guid><description>&lt;p>This project involved exploratory analysis of a movie ratings dataset, with the goal of predicting the rating a user would give to a movie based on ratings from other users.&lt;/p>
&lt;p>Two manually built linear regression models were used to predict ratings: one based solely on users and their ratings, and another incorporating movie metadata as well.&lt;/p>
&lt;p>The FunkSVD model was also implemented.&lt;/p>
&lt;p>The methodology included selecting the best hyperparameters through cross-validation, as well as choosing the final model based on RMSE and MAE metrics. Additionally, Precision@k, Recall@k, F1@k, and MRR@k metrics were used to evaluate the recommendation models&amp;rsquo; performance.&lt;/p></description></item><item><title>Frequent Word Analysis in Books</title><link>https://hugoverissimo21.github.io/projects/frequentwordfinder/</link><pubDate>Tue, 24 Dec 2024 00:00:00 +0000</pubDate><guid>https://hugoverissimo21.github.io/projects/frequentwordfinder/</guid><description>&lt;p>Using the online Project Gutenberg library, three translations of the book &lt;em>Pinocchio&lt;/em>—in English, Italian, and Finnish—were selected. The goal of the project was to apply and compare different word counting algorithms to identify the most frequent words in each version, and to analyze similarities and differences between the texts.&lt;/p>
&lt;p>Three types of algorithms were used:&lt;/p>
&lt;ul>
&lt;li>exact counters,&lt;/li>
&lt;li>probabilistic counters (such as hash-based methods),&lt;/li>
&lt;li>space-saving counters (with memory optimization).&lt;/li>
&lt;/ul>
&lt;p>The analysis involved:&lt;/p></description></item><item><title>Media Coverage Analysis of PSI-20 Companies</title><link>https://hugoverissimo21.github.io/projects/infomosaic/</link><pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><guid>https://hugoverissimo21.github.io/projects/infomosaic/</guid><description>&lt;p>The main goal of this project is to analyze media coverage of companies listed on the PSI-20 index. Using data analysis, machine learning, and visualization techniques, the project aims to extract relevant insights about public perception and sentiment surrounding these companies.&lt;/p>
&lt;p>The specific objectives and features of the project include:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Sentiment Analysis&lt;br>
Assess the sentiment in news articles and media coverage to determine whether keywords associated with PSI-20 companies have a positive or negative impact on public perception.&lt;/p></description></item><item><title>Fatigue Classification in Competitive Swimmers</title><link>https://hugoverissimo21.github.io/projects/swimml-fatiguemonitor/</link><pubDate>Wed, 27 Nov 2024 00:00:00 +0000</pubDate><guid>https://hugoverissimo21.github.io/projects/swimml-fatiguemonitor/</guid><description>&lt;p>This project focuses on applying Machine Learning to estimate fatigue levels in swimmers, with the goal of preventing overuse injuries.&lt;/p>
&lt;p>Data was collected from a local swimming team, covering multiple athletes. Data preprocessing was conducted to ensure quality, integrity, and suitability for machine learning algorithms.&lt;/p>
&lt;p>Feature engineering extracted relevant variables from raw data, notably using EWMA (Exponentially Weighted Moving Average).&lt;/p>
&lt;p>Models such as Support Vector Machine (SVM), logistic regression, and decision trees were used to classify data into three fatigue levels.&lt;/p></description></item><item><title>Maximum Cut Problem (Max-Cut)</title><link>https://hugoverissimo21.github.io/projects/max-weighted-cut/</link><pubDate>Sat, 09 Nov 2024 00:00:00 +0000</pubDate><guid>https://hugoverissimo21.github.io/projects/max-weighted-cut/</guid><description>&lt;p>The Maximum Cut (Max-Cut) problem is an NP-hard problem that consists of dividing a graph into two subsets with the objective of maximizing the weight of the edges cut between them. This project focuses on solving the problem using both deterministic and stochastic algorithms, including Simulated Annealing.&lt;/p>
&lt;p>The work is divided into two main approaches:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Deterministic algorithms:&lt;br>with implementations of exhaustive search and greedy search for exact or approximate solutions.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Stochastic algorithms:&lt;br>including methods such as Random Cut, Simulated Annealing, and Greedy Randomized approaches, which seek approximate solutions efficiently.&lt;/p></description></item></channel></rss>